{"version":3,"file":"index.js","sourceRoot":"","sources":["../../../src/@ionic-native/plugins/cloud-speech-to-text/index.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;AAAA,OAAO,EAAE,UAAU,EAAE,MAAM,eAAe,CAAC;AAC3C,OAAO,EAAE,OAAO,EAAE,MAAM,EAAE,iBAAiB,EAAE,MAAM,oBAAoB,CAAC;AACxE,OAAO,EAAE,UAAU,EAAE,MAAM,iBAAiB,CAAC;;;;;;;;;;;;;;;;;;;;;;;IAgDN,qCAAiB;;;;IAEtD;;;OAGG;;;;;IAEH,gDAAoB;;;;;QAClB,MAAM,CAAC,IAAI,CAAC;KACb;IAED;;;;OAIG;;;;;;IAEH,qCAAS;;;;;cAAC,MAAsC;QAC9C,MAAM,CAAC;KACR;IAED;;;OAGG;;;;;IAEH,4CAAgB;;;;cAAC,aAAyB;QACxC,MAAM,CAAC;KACR;IAED;;;OAGG;;;;;IAEH,0CAAc;;;;;QACZ,MAAM,CAAC;KACR;IAED;;OAEG;;;;IAEH,yCAAa;;;;QACX,MAAM,CAAC;KACR;IAED;;;OAGG;;;;;IAEH,wCAAY;;;;;QACV,MAAM,CAAC;KACR;IAED;;;;OAIG;;;;;;IAEH,qCAAS;;;;;cAAC,KAAa;QACrB,MAAM,CAAC;KACR;IAED;;;;OAIG;;;;;;IAIH,0CAAc;;;;;cAAC,SAAiB;QAC9B,MAAM,CAAC;KACR;IAED;;OAEG;;;;IAEH,yCAAa;;;;QACX,MAAM,CAAC;KACR;;gBArFF,UAAU;;;QAOR,OAAO,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,CAAC;;;;iEAGvB;;QAOA,OAAO,EAAE;;;;sDAGT;;QAMA,OAAO,EAAE;;yCACsB,KAAK;;6DAEpC;;QAMA,OAAO,EAAE;;;;2DAGT;;QAKA,OAAO,EAAE;;;;0DAGT;;QAMA,OAAO,EAAE;;;;yDAGT;;QAOA,OAAO,EAAE;;;;sDAGT;;QAOA,OAAO,CAAC;YACP,UAAU,EAAE,IAAI;SACjB,CAAC;;;wCACiC,UAAU;2DAE5C;;QAKA,OAAO,EAAE;;;;0DAGT;;;;;;;;;;;;;;;;;;;;;;IApFU,iBAAiB;QAV7B,MAAM,CAAC;YACN,UAAU,EAAE,mBAAmB;YAC/B,MAAM,EAAE,qCAAqC;;YAC7C,SAAS,EAAE,mCAAmC;;YAC9C,IAAI,EAAE,+EAA+E;;YACrF,OAAO,EAAE,EAAE;;YACX,gBAAgB,EAAE,EAAE;;YACpB,SAAS,EAAE,CAAC,KAAK,CAAC;SACnB,CAAC;OAEW,iBAAiB,EAsF7B;4BAxID;EAkDuC,iBAAiB;SAA3C,iBAAiB","sourcesContent":["import { Injectable } from '@angular/core';\nimport { Cordova, Plugin, IonicNativePlugin } from '@ionic-native/core';\nimport { Observable } from 'rxjs/Observable';\n\nexport interface CloudSpeechToTextConfiguration {\n  apiKey?: string;\n  languageCode?: string;\n  maxAlternatives?: number;\n  audioEncoding?: string;\n  sampleRate?: number;\n  bufferSize?: number;\n}\n\nexport interface SpeechRecognitionResponse {\n  requestId: string;\n  results: Array<any>;\n  isFinal: boolean;\n}\n\n/**\n * @name Cloud Speech Recognition\n * @description\n * This plugin does something\n *\n * @usage\n * ```typescript\n * import { CloudSpeechToText } from '@ionic-native/cloud-speech-to-text';\n *\n *\n * constructor(private cloudSpeechToText: CloudSpeechToText) { }\n *\n * ...\n *\n *\n * this.cloudSpeechToText.functionName('Hello', 123)\n *   .then((res: any) => console.log(res))\n *   .catch((error: any) => console.error(error));\n *\n * ```\n */\n@Plugin({\n  pluginName: 'CloudSpeechToText',\n  plugin: 'cordova-plugin-cloud-speech-to-text', // npm package name, example: cordova-plugin-camera\n  pluginRef: 'cordova.plugins.CloudSpeechToText', // the variable reference to call the plugin, example: navigator.geolocation\n  repo: 'https://betacut@bitbucket.org/betacut/cordova-plugin-cloud-speech-to-text.git', // the github repository URL for the plugin\n  install: '', // OPTIONAL install command, in case the plugin requires variables\n  installVariables: [], // OPTIONAL the plugin requires variables\n  platforms: ['iOS'] // Array of platforms supported, example: ['Android', 'iOS']\n})\n@Injectable()\nexport class CloudSpeechToText extends IonicNativePlugin {\n\n  /**\n   * Returns that plugin has streaming support.\n   * @return {boolean} Returns that plugin has streaming support.\n   */\n  @Cordova({ sync: true })\n  isStreamingAvailable(): boolean {\n    return true;\n  }\n\n  /**\n   * Configures plugin.\n   * @param {CloudSpeechToTextConfiguration} config Cloud Speech-to-Text configuration options.\n   * @return {Promise<void>} Returns a promise that resolves when plugin was initialized.\n   */\n  @Cordova()\n  configure(config: CloudSpeechToTextConfiguration): Promise<void> {\n    return;\n  }\n\n  /**\n   * Sets speech context.\n   * @param {Array<any>} speechContext Speech context.\n   */\n  @Cordova()\n  setSpeechContext(speechContext: Array<any>): void {\n    return;\n  }\n\n  /**\n   * Starts recording microphone input.\n   * @return {Promise<void>} Returns a promise that resolves after recording was started.\n   */\n  @Cordova()\n  startRecording(): Promise<void> {\n    return;\n  }\n\n  /**\n   * Stops recording microphone input.\n   */\n  @Cordova()\n  stopRecording(): void {\n    return;\n  }\n\n  /**\n   * Gets the audio recording as base64 string.\n   * @return {Promise<string>} Returns a promise that resolves after audio recording was converted into base64 string.\n   */\n  @Cordova()\n  getRecording(): Promise<string> {\n    return;\n  }\n\n  /**\n   * Recognizes text from an audio base64 encoded string.\n   * @param {string} audio Audio input containing intent.\n   * @return {Promise<SpeechRecognitionResponse>} Returns a promise containing detect intent response.\n   */\n  @Cordova()\n  recognize(audio: string): Promise<SpeechRecognitionResponse> {\n    return; // We add return; here to avoid any IDE / Compiler errors\n  }\n\n  /**\n   * Starts listening to microphone input.\n   * @param {string} requestId Request id.\n   * @return {Observable<SpeechRecognitionResponse>} Returns a observable containing streaming detect intent response.\n   */\n  @Cordova({\n    observable: true\n  })\n  startListening(requestId: string): Observable<SpeechRecognitionResponse> {\n    return;\n  }\n\n  /**\n   * Stops listening to microphone input.\n   */\n  @Cordova()\n  stopListening(): void {\n    return;\n  }\n\n}\n"]}